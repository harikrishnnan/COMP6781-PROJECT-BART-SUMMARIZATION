{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5675bc3-1beb-4631-a49b-9c1a5633be33",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fe1be82-0d34-4514-937f-5340e73ceebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/b/bergler/h_gurush/tmp/jupyter-envs/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "from transformers import BartTokenizer, BartModel, BartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "178c4db6-5680-4236-bb22-37e353890270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "169247f7-b808-426d-a8b8-a867f00133dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4ab1f2-953b-4a49-94d9-beeffd10df5b",
   "metadata": {},
   "source": [
    "# Get Dataset from arXiv and PubMed(10 each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd8ff406-c6bc-4b8a-8715-77159911d5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_arXiv_pubMed():\n",
    "    content={}\n",
    "    articles={}\n",
    "    with open(\"Dataset/arxiv-dataset/test.txt\",\"r\") as w:\n",
    "        for index,line in enumerate(w.readlines()):\n",
    "            if index==1000:\n",
    "                break\n",
    "            content=json.loads(line)\n",
    "            articles[content[\"article_id\"]]=content\n",
    "    pubmedArticles={}\n",
    "    with open(\"Dataset/pubmed-dataset/test.txt\",\"r\") as w:\n",
    "        for index,line in enumerate(w.readlines()):\n",
    "            if index==1000:\n",
    "                break\n",
    "            content=json.loads(line)\n",
    "            pubmedArticles[content[\"article_id\"]]=content\n",
    "\n",
    "    return articles, pubmedArticles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8451e7a2-522f-4f90-b633-63432748ef10",
   "metadata": {},
   "source": [
    "### GET MODELS (FINE TUNED and VANILLA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5fa622d-1f3e-412d-9937-8b82ebd47a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartModel, BartForConditionalGeneration\n",
    "\n",
    "def get_model_and_tokenizer(modelName='facebook/bart-large-cnn'):\n",
    "    tokenizer = BartTokenizer.from_pretrained(modelName)\n",
    "    model = BartForConditionalGeneration.from_pretrained(modelName).to(device)\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a34f8b84-24a9-462a-bf3c-b58025d63ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fine_tuned_model(modelName=\"BART-E5-ALL.pth\"):\n",
    "    model=BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\").to(device)\n",
    "    model.load_state_dict(torch.load(modelName))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65bd3bd1-0a67-4fcf-bb50-62b3443ba6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def section_text_cleaning(sectionText):\n",
    "    section_text=[]\n",
    "    math_mappings={}\n",
    "    for section in sectionText:\n",
    "        cleaned_text=[]\n",
    "        for i in section:\n",
    "            text=i.replace(\"@xcite\",\"\")\n",
    "            for j in text.split():\n",
    "                if \"@xmath\" in j:\n",
    "                    if j in math_mappings:\n",
    "                        text=text.replace(j,math_mappings[j])\n",
    "                    else:\n",
    "                        math_mappings[j]=\"[equation\"+str(len(math_mappings))+\"]\"\n",
    "                        text=text.replace(j,math_mappings[j])\n",
    "            cleaned_text.append(text)\n",
    "        section_text.append(cleaned_text)\n",
    "    return section_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13d8d843-c229-48a7-be8c-0f4b56c5afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_text_cleaning(docText):\n",
    "    cleaned_text=[]\n",
    "    math_mappings={}\n",
    "    for i in docText:   \n",
    "        text=i.replace(\"@xcite\",\"\")\n",
    "        for j in text.split():\n",
    "            if \"@xmath\" in j:\n",
    "                if j in math_mappings:\n",
    "                    text=text.replace(j,math_mappings[j])\n",
    "                else:\n",
    "                    math_mappings[j]=\"[equation\"+str(len(math_mappings))+\"]\"\n",
    "                    text=text.replace(j,math_mappings[j])\n",
    "        cleaned_text.append(text)\n",
    "        \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7acfeed8-4486-4cd4-b9c7-6b0ff09951c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def handle_size(tokens,default=1000,percent=0.2):\n",
    "    chunked_ip=[]\n",
    "    \n",
    "    #print(tokens.shape[1]/(default-(default*percent)))\n",
    "    for index in range(math.ceil(tokens.shape[1]/(default))):\n",
    "        if index==0:\n",
    "            chunked_ip.append(tokens[ : ,0:default])\n",
    "        else:\n",
    "            st_index=index*math.floor(default-(default*percent))\n",
    "            \n",
    "            \n",
    "            chunked_ip.append(tokens[ : ,st_index: st_index+default])\n",
    "    \n",
    "    return chunked_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39b02f96-60f5-49bc-8537-84e52100db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_from_sections(section_texts,model,tokenizer):\n",
    "    summary=\"\"\n",
    "    for i in section_texts:\n",
    "        #print(\"before\")\n",
    "        #handle size\n",
    "        \n",
    "        tokens=tokenizer([\" \".join(i)],max_length=1000,padding=\"max_length\",return_tensors=\"pt\")\n",
    "        #print(tokens['input_ids\n",
    "        #print(tokens[\"input_ids\"].shape[1])\n",
    "        if tokens[\"input_ids\"].shape[1]>=1024:\n",
    "            chunked_ip=handle_size(tokens[\"input_ids\"])\n",
    "            for j in chunked_ip:\n",
    "                #print(j.shape)\n",
    "                gen_tokens=model.generate(j.to(device),num_beams=4, min_length=50,max_length=100, early_stopping=True)\n",
    "                decode=tokenizer.batch_decode(gen_tokens,skip_special_tokens=True)\n",
    "                summary+=\" \".join(decode)+\"\\n\"\n",
    "            continue\n",
    "        \n",
    "        #print(\"error\",tokens['input_ids'].shape)\n",
    "        gen_tokens=model.generate(tokens[\"input_ids\"].to(device),num_beams=4, min_length=50,max_length=100, early_stopping=True)\n",
    "        decode=tokenizer.batch_decode(gen_tokens,skip_special_tokens=True)\n",
    "        summary+=\" \".join(decode)+\"\\n\"\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a87193bc-e592-4792-a143-657a583b0607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "def evaluate_summary(summary,reference):\n",
    "    # Initialize the rouge metric\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    results = rouge.compute(predictions=[summary], references=[reference])\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8daa11-28e5-4cac-973d-73e1e0ba381c",
   "metadata": {},
   "source": [
    "## Centrality Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59351881-9f8a-4436-96d6-1cabeb326d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f26b21b4-e00c-4696-849f-2420213db236",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def create_cosine_matrix(threshold,sent_emb_map):\n",
    "    \n",
    "    #sentence_matrix=[]        \n",
    "    # Calculate pairwise cosine similarity\n",
    "    #for sentence in sentBow[cluster]:\n",
    "    #print(torch.stack(list(cluster_embeddings[cluster].values())).squeeze(1).shape)\n",
    "    similarity_matrix = cosine_similarity(list(sent_emb_map.values()))\n",
    "    for i in range(0,similarity_matrix.shape[0]):\n",
    "        for j in range(0,similarity_matrix.shape[0]):\n",
    "            if similarity_matrix[i,j]>=threshold:\n",
    "                similarity_matrix[i,j]=1\n",
    "            else:\n",
    "                similarity_matrix[i,j]=0\n",
    "        # normalize row by div each element in the row with row sum\n",
    "        similarity_matrix[i]=similarity_matrix[i]/sum(similarity_matrix[i])\n",
    "        \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e84f1001-2686-46fe-8a95-fd8f5323cb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_transition_matrix(similarity_matrix):\n",
    "    #develop aperodic ,irreducible transition matrix\n",
    "    #damping factor [0.1,0.2]\n",
    "    d=0.1\n",
    "    #uniform probality\n",
    "    uniform_matrix= np.full((1, similarity_matrix.shape[0]), 1 / similarity_matrix.shape[0])\n",
    "    dU=d*uniform_matrix\n",
    "    d_B=(1-d)*similarity_matrix\n",
    "    transition_Matrix=dU+d_B\n",
    "    transition_Matrix=transition_Matrix.T\n",
    "    return transition_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1231965-2c51-4c9b-a3d8-ea8673a0f2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def compute_centrality(transition_Matrix,threshold):\n",
    "    N=transition_Matrix.shape[0]\n",
    "    p0=np.full(N, 1 / N)\n",
    "    t=0\n",
    "    while True:\n",
    "        t=t+1\n",
    "        #p1=transition_Matrix*p0\n",
    "        p1 = transition_Matrix @ p0\n",
    "        error=np.linalg.norm(p1 - p0)\n",
    "        # print(\"p1\",p1.shape,p0.shape)\n",
    "        # print(\"loop\",t)\n",
    "        if error<threshold:\n",
    "            return p1\n",
    "        p0=p1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39fcf323-d0f0-4c94-a566-a44cb5196cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_lexrank(sentMatrices):\n",
    "   \n",
    "    t_matrix=compute_transition_matrix(sentMatrices)\n",
    "    sent_rank=compute_centrality(t_matrix, 1e-6).tolist()\n",
    "    return sent_rank  \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c5b6416-4f1f-49a9-87ff-bcf43891309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer=BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "# model=BertModel.from_pretrained(\"bert-base-cased\").to(device)\n",
    "sent_model=SentenceTransformer('sentence-transformers/paraphrase-MiniLM-L6-v2').to(device)\n",
    "def centroidTfIdf(sentences):\n",
    "    if not all(isinstance(sentence, str) for sentence in sentences):\n",
    "        print(\"All elements in `sentences` must be strings.\",sentences)\n",
    "   \n",
    "        \n",
    "    #sentences=sent_tokenize(\" \".join(clusterContent[clusterContent[\"cluster\"]==cluster][\"content\"]))\n",
    "    embeddings = sent_model.encode(sentences)\n",
    "    #print(type(sentences))\n",
    "    #print(type(embeddings))\n",
    "    sent_list=dict(zip(sentences,embeddings))\n",
    "    #print(\"passed\")\n",
    "  \n",
    "    return sent_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20c13d2b-acce-451a-8df7-7d29ef087263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDocSents_Ranking(text):\n",
    "    #compression rate\n",
    "    r=0.2#0.2\n",
    "    \n",
    "    sent_emb_map=centroidTfIdf(text)\n",
    "    sim_matrix=create_cosine_matrix(0.5,sent_emb_map)# should be 0.5\n",
    "    sent_ranks=compute_lexrank(sim_matrix)\n",
    "    mapped_score=tuple(zip(list(sent_emb_map.keys()),sent_ranks))\n",
    "    \n",
    "    sorted_scores=sorted(mapped_score,key=lambda x:x[1],reverse=True)\n",
    "    n=math.ceil(len(sent_emb_map)*r)\n",
    "    ranked_sents=list(dict(islice(sorted_scores,0,n)).keys())\n",
    "    ordered_sents=[]\n",
    "    for i in sent_emb_map:\n",
    "        if i in ranked_sents:\n",
    "            ordered_sents.append(i)\n",
    "    count_tokens=0\n",
    "    removed_sents=[]\n",
    "    for i in ordered_sents:\n",
    "        if len(i.split())+count_tokens > 1000:\n",
    "            break\n",
    "        else:\n",
    "            removed_sents.append(i)\n",
    "            count_tokens+=len(i.split())\n",
    "    #print(removed_sents)\n",
    "    return removed_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d7688f-a4d0-47b0-b8c1-b1fad9b5bb8c",
   "metadata": {},
   "source": [
    "## create summary from summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9803ab42-e8c0-44fa-b699-beb6f3983586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_from_summary(section_texts,model,tokenizer):\n",
    "   \n",
    "    summary=\"\"\n",
    "      \n",
    "    #print(\"before\")\n",
    "    #handle size\n",
    "    \n",
    "    tokens=tokenizer(section_texts ,max_length=1000,padding=\"max_length\",return_tensors=\"pt\")\n",
    "    #print(tokens['input_ids\n",
    "    #print(\"here\",tokens[\"input_ids\"][0].shape)\n",
    "    if tokens[\"input_ids\"].shape[1]>=1024:\n",
    "        chunked_ip=handle_size(tokens[\"input_ids\"],1000,0.4)\n",
    "        for j in chunked_ip:\n",
    "            #print(j.shape)\n",
    "            gen_tokens=model.generate(j.to(device),num_beams=4, min_length=50,max_length=100, early_stopping=True)\n",
    "            decode=tokenizer.batch_decode(gen_tokens,skip_special_tokens=True)\n",
    "            summary+=\" \".join(decode)+\"\\n\"\n",
    "        return summary\n",
    "    \n",
    "    #print(\"error\",tokens['input_ids'].shape)\n",
    "    gen_tokens=model.generate(tokens[\"input_ids\"].to(device),num_beams=4, min_length=150,max_length=300, early_stopping=True)\n",
    "    decode=tokenizer.batch_decode(gen_tokens,skip_special_tokens=True)\n",
    "    summary+=\" \".join(decode)+\"\\n\"\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf78d60f-cd6f-4280-8355-2a66be82694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "def sentSplitter(content):\n",
    "    sentences=sent_tokenize(content)\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddb4233-dc1b-4fa7-8b3a-667491196fa5",
   "metadata": {},
   "source": [
    "# Running pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cf6b40-e4b9-45cf-98e4-7dc9b2cc7774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#get data\n",
    "from evaluate import load\n",
    "from tqdm import tqdm\n",
    "arXiv_articles, pubMed_articles=get_data_from_arXiv_pubMed()\n",
    "bertscore = load(\"bertscore\")\n",
    "bleu = evaluate.load(\"google_bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "#initialize model\n",
    "model, tokenizer = get_model_and_tokenizer()\n",
    "\n",
    "fine_model = get_fine_tuned_model()\n",
    "\n",
    "pubMed_scores={\"rouge\":[],\"bleu\":[],\"bertScore\":[]}\n",
    "arXiv_scores={\"rouge\":[],\"bleu\":[],\"bertScore\":[]}\n",
    "section_summary=[]\n",
    "section_fine_summary=[]\n",
    "ranked_summaries=[]\n",
    "ranked_fine_summaries=[]\n",
    "try:\n",
    "    for index,value in enumerate(tqdm(arXiv_articles)):\n",
    "        article=arXiv_articles[value]\n",
    "        section_text=section_text_cleaning(article['sections'])\n",
    "        article_text=doc_text_cleaning(article[\"article_text\"])\n",
    "        doc_sentences=getDocSents_Ranking(article_text)\n",
    "        ranked_summary=create_summary_from_summary(\" \".join(doc_sentences),model, tokenizer)\n",
    "        ranked_fine_summary=create_summary_from_summary(\" \".join(doc_sentences),model, tokenizer)\n",
    "        #generate summary\n",
    "        summary=create_summary_from_sections(section_text,model, tokenizer)\n",
    "        fine_tuned_summary=create_summary_from_sections(section_text,fine_model, tokenizer)\n",
    "        #print(\"summary\",summary)\n",
    "        overall_summary=create_summary_from_summary([summary],model,tokenizer)\n",
    "        overall_fine_summary=create_summary_from_summary([fine_tuned_summary],fine_model,tokenizer)\n",
    "        #evaluate summary\n",
    "        if index%50==0:\n",
    "            section_fine_summary.append(overall_fine_summary)\n",
    "            section_summary.append(overall_summary)\n",
    "            ranked_summaries.append(ranked_summary)\n",
    "            ranked_fine_summaries.append(ranked_fine_summary)\n",
    "        #evaluaate\n",
    "        reference=\" \".join(article['abstract_text']).replace(\"<S>\",\"\").replace(\"</S>\",\"\")\n",
    "        arXiv_scores[\"bertScore\"].append(bertscore.compute(predictions=[overall_summary],references=[reference], lang=\"en\"))\n",
    "        arXiv_scores[\"bertScore\"].append(bertscore.compute(predictions=[overall_fine_summary],references=[reference], lang=\"en\"))\n",
    "        arXiv_scores[\"bertScore\"].append(bertscore.compute(predictions=[ranked_summary],references=[reference], lang=\"en\"))\n",
    "        arXiv_scores[\"bertScore\"].append(bertscore.compute(predictions=[ranked_fine_summary],references=[reference], lang=\"en\"))\n",
    "\n",
    "        #BLEU\n",
    "        arXiv_scores[\"bleu\"].append(bleu.compute(predictions=[overall_summary],references=[reference]))\n",
    "        arXiv_scores[\"bleu\"].append(bleu.compute(predictions=[overall_fine_summary],references=[reference]))\n",
    "        arXiv_scores[\"bleu\"].append(bleu.compute(predictions=[ranked_summary],references=[reference]))\n",
    "        arXiv_scores[\"bleu\"].append(bleu.compute(predictions=[ranked_fine_summary],references=[reference]))\n",
    "\n",
    "        #ROUGE\n",
    "        arXiv_scores[\"rouge\"].append(rouge.compute(predictions=[overall_summary],references=[reference]))\n",
    "        arXiv_scores[\"rouge\"].append(rouge.compute(predictions=[overall_fine_summary],references=[reference]))\n",
    "        arXiv_scores[\"rouge\"].append(rouge.compute(predictions=[ranked_summary],references=[reference]))\n",
    "        arXiv_scores[\"rouge\"].append(rouge.compute(predictions=[ranked_fine_summary],references=[reference]))\n",
    "        if index%100==0:\n",
    "            pickle.dump(arXiv_scores,open(\"arxiv_Scores.pickle\",\"wb\"))\n",
    "            #pickle.dump(pubMed_scores,open(\"pubMed_scores.pickle\",\"wb\"))\n",
    "            torch.cuda.empty_cache()\n",
    "    for index,value in enumerate(tqdm(pubMed_articles)):\n",
    "        article=pubMed_articles[value]\n",
    "        section_text=section_text_cleaning(article['sections'])\n",
    "        article_text=doc_text_cleaning(article[\"article_text\"])\n",
    "        doc_sentences=getDocSents_Ranking(article_text)\n",
    "        ranked_summary=create_summary_from_summary(\" \".join(doc_sentences),model, tokenizer)\n",
    "        ranked_fine_summary=create_summary_from_summary(\" \".join(doc_sentences),model, tokenizer)\n",
    "        #generate summary\n",
    "        summary=create_summary_from_sections(section_text,model, tokenizer)\n",
    "        fine_tuned_summary=create_summary_from_sections(section_text,fine_model, tokenizer)\n",
    "        #print(\"summary\",summary)\n",
    "        overall_summary=create_summary_from_summary([summary],model,tokenizer)\n",
    "        overall_fine_summary=create_summary_from_summary([fine_tuned_summary],fine_model,tokenizer)\n",
    "        #evaluate summary\n",
    "        if index%50==0:\n",
    "            section_fine_summary.append(overall_fine_summary)\n",
    "            section_summary.append(overall_summary)\n",
    "            ranked_summaries.append(ranked_summary)\n",
    "            ranked_fine_summaries.append(ranked_fine_summary)\n",
    "        #evaluaate\n",
    "        reference=\" \".join(article['abstract_text']).replace(\"<S>\",\"\").replace(\"</S>\",\"\")\n",
    "        pubMed_scores[\"bertScore\"].append(bertscore.compute(predictions=[overall_summary],references=[reference], lang=\"en\"))\n",
    "        pubMed_scores[\"bertScore\"].append(bertscore.compute(predictions=[overall_fine_summary],references=[reference], lang=\"en\"))\n",
    "        pubMed_scores[\"bertScore\"].append(bertscore.compute(predictions=[ranked_summary],references=[reference], lang=\"en\"))\n",
    "        pubMed_scores[\"bertScore\"].append(bertscore.compute(predictions=[ranked_fine_summary],references=[reference], lang=\"en\"))\n",
    "\n",
    "        #BLEU\n",
    "        pubMed_scores[\"bleu\"].append(bleu.compute(predictions=[overall_summary],references=[reference]))\n",
    "        pubMed_scores[\"bleu\"].append(bleu.compute(predictions=[overall_fine_summary],references=[reference]))\n",
    "        pubMed_scores[\"bleu\"].append(bleu.compute(predictions=[ranked_summary],references=[reference]))\n",
    "        pubMed_scores[\"bleu\"].append(bleu.compute(predictions=[ranked_fine_summary],references=[reference]))\n",
    "\n",
    "        #ROUGE\n",
    "        pubMed_scores[\"rouge\"].append(rouge.compute(predictions=[overall_summary],references=[reference]))\n",
    "        pubMed_scores[\"rouge\"].append(rouge.compute(predictions=[overall_fine_summary],references=[reference]))\n",
    "        pubMed_scores[\"rouge\"].append(rouge.compute(predictions=[ranked_summary],references=[reference]))\n",
    "        pubMed_scores[\"rouge\"].append(rouge.compute(predictions=[ranked_fine_summary],references=[reference]))\n",
    "        if index%100==0:\n",
    "            #pickle.dump(arXiv_scores,open(\"arxiv_Scores.pickle\",\"wb\"))\n",
    "            pickle.dump(pubMed_scores,open(\"pubMed_scores.pickle\",\"wb\"))\n",
    "            torch.cuda.empty_cache()\n",
    "except Exception as e:\n",
    "    print(\"error\",e)\n",
    "    \n",
    "finally:\n",
    "    pickle.dump(arXiv_scores,open(\"arxiv_Scores.pickle\",\"wb\"))\n",
    "    pickle.dump(pubMed_scores,open(\"pubMed_scores.pickle\",\"wb\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4bd80d-b446-431c-ae53-8e2b3941b70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(section_fine_summary,open(\"fine summary.pickle\",\"wb\"))\n",
    "pickle.dump(ranked_summaries,open(\"ranked summary.pickle\",\"wb\"))\n",
    "pickle.dump(section_summary,open(\"summary.pickle\",\"wb\"))\n",
    "pickle.dump(ranked_fine_summaries,open(\"ranked fine summary.pickle\",\"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
